### hive创建表文件格式和压缩方式

#### ORC建表配置属性
	tblproperties ('orc.compress'='snappy');
	orc.compress:表示ORC文件的压缩类型， 「可选的类型有NONE、ZLB和SNAPPY，默认值是ZLIB（Snappy不支持切片）」---这个配置是最关键的
	orc.compress.size:表示压缩块( chunk)的大小,默认值是262144(256KB)。
	orc.stripe.size:写 stripe,可以使用的内存缓冲池大小,默认值是67108864(64MB）
	orc.row.index.stride:行组级别索引的数据量大小,默认是10000,必须要设置成大于等于10000的数
	orc.createindex:是否创建行组级别索引,默认是true
	orc.bloomfilter.columns:需要创建布隆过滤的组。
	orc.bloomfilterfpp:使用布隆过滤器的假正( False Positive)概率,默认值是0.



#### PARQUET建表配置属性

	parquet.blocksize:默认值为134217728byte,即128MB,表示 Row Group在内存中的块大小。该值设置得大,可以提升 Parquet文件的读取效率,但是相应在写的时候需要耗费更多的内存
	parquet.pagesize:默认值为1048576byt,即1MB,表示每个页(page)的大小。这个特指压缩后的页大小,在读取时会先将页的数据进行解压。页是 Parquet操作数据的最小单位,每次读取时必须读完一整页的数据才能访问数据。这个值如果设置得过小,会导致压缩时出现性能问题
	parquet.compression:默认值为 UNCOMPRESSED，表示页的压缩方式。 **「可以使用的压缩方式有 UNCOMPRESSED、 SNAPPY、GZP和LZO」**。
	Parquetenable.dictionary:默认为tue,表示是否启用字典编码。
	parquet.dictionarypage.size:默认值为1048576byte,即1MB。在使用字典编码时,会在 Parquet的每行每列中创建一个字典页。使用字典编码,如果存储的数据页中重复的数据较多,能够起到一个很好的压缩效果,也能减少每个页在内存的占用。

#### 压缩方式

| 格式   | 可分割             | 平均压缩速度 | 文本文件压缩效率 | Hadoop压缩编解码器                         | 纯Java实现 | **原生** | **备注**                                           |
| ------ | ------------------ | ------------ | ---------------- | ------------------------------------------ | ---------- | -------- | -------------------------------------------------- |
| gzip   | 否                 | 快           | 高               | org.apache.hadoop.io.compress.GzipCodec    | 是         | 是       |                                                    |
| lzo    | 是(取决于使用的库) | 非常快       | 中等             | com.hadoop.compression.lzo.LzoCodec        | 是         | 是       | 需要在每个节点上安装LZO                            |
| bzip2  | 是                 | 慢           | 非常高           | org.apache.hadoop.io.compress.Bzip2Codec   | 是         | 是       | 为可分割版本使用纯java                             |
| zlib   | 否                 | 慢           | 中等             | org.apache.hadoop.io.compress.DefaultCodec | 是         | 是       | Hadoop的默认压缩编解码器                           |
| snappy | 否                 | 非常快       | 低               | org.apache.hadoop.io.compress.SnappyCodec  | 否         | 是       | snappy有纯java的移植版，但是在Spark/Hadoop中不能用 |




#### textfile 无压缩

	-rwxrwxrwt  hdfs	hive	943.07 MB	Sep 30 11:25	3	128 MB	test.txt	
	一共分成了8个block

#### parquet+snappy

```sql
  create table num_parquet_snappy(num bigint) 
    row format delimited fields terminated by "\t"
    stored as parquet 
    tblproperties("parquet.compress"="snappy");
```

  	-rw-r--r--	hdfs	hive	0 B	Oct 08 14:31	3	128 MB	_SUCCESS	
  	-rw-r--r--	hdfs	hive	558.39 MB	Oct 08 14:31	3	128 MB	part-00000-6c1ebcac-3402-4658-85ce-ab94aa68cf9c-c000.snappy.parquet	

#### parquet+gzip

```sql
  create table num_parquet_gzip(num bigint) 
    row format delimited fields terminated by "\t"
    stored as orc 
    tblproperties("parquet.compress"="gzip");
```


  	-rw-r--r--	hdfs	hive	0 B	Oct 08 15:27	3	128 MB	_SUCCESS	
  	-rw-r--r--	hdfs	hive	409.02 MB	Oct 08 15:27	3	128 MB	part-00000-69ea725e-7b26-4985-a393-fbbedf7d27b3-c000.gz.parquet

#### orc+snappy

```sql
  create table num_orc_snappy(num bigint) 
    row format delimited fields terminated by "\t"
    stored as orc 
    tblproperties("orc.compress"="snappy");
```


  	-rw-r--r--	hdfs	hive	0 B	Oct 08 14:22	3	128 MB	_SUCCESS	
  	-rw-r--r--	hdfs	hive	382.1 MB	Oct 08 14:22	3	256 MB	part-00000-fee51561-a00a-4133-9eb7-6ae7e829e840-c000.snappy.orc

#### orc+zlib

```sql
  create table num_orc_zlib(num bigint) 
    row format delimited fields terminated by "\t"
    stored as orc 
    tblproperties("orc.compress"="zlib");
```


  	-rw-r--r--	hdfs	hive	0 B	Oct 08 15:42	3	128 MB	_SUCCESS	
  	-rw-r--r--	hdfs	hive	363.61 MB	Oct 08 15:42	3	256 MB	part-00000-5c2bd429-b8cd-4ae1-b35d-3b7446379c9b-c000.zlib.orc

##### 在实际生产中，使用parquet存储，lzo压缩的方式更为常见，这种情况下可以避免由于读取不可分割大文件引发的数据倾斜。但是如果数据量不大（预测不会有超大文件，若干G以上）的情况下，使用orc存储，snappy压缩的效率还是非常高的。
